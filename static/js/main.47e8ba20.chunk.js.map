{"version":3,"sources":["Figures/cnn_3.png","Figures/Emotions/happy.png","Figures/Emotions/surprise.png","Figures/Emotions/sad.png","Figures/Emotions/angry.png","Figures/Emotions/fear.png","Figures/Emotions/neutral.png","Figures/silas.jpg","Figures/rama.jpg","Figures/maria.png","Figures/UW.png","components/ImplementationScreen.js","components/ResultsScreen.js","components/StreamScreen.js","components/WelcomeScreen.js","components/ProjectProposal.js","components/Navigator.js","index.js"],"names":["module","exports","__webpack_require__","p","ImplementationScreen","React","createElement","Container","className","id","Zoom","src","cnnPic","alt","width","happyPic","surprisePic","angryPic","sadPic","fearPic","neutralPic","ResultsScreen","StreamScreen","video","useRef","canvas","useEffect","Row","Col","height","autoPlay","ref","WelcomeScreen","ramaPic","silasPic","mariaPic","ProjectProposal","href","Navigator","fluid","uwLogo","ReactDOM","createRoot","document","getElementById","render","StrictMode","xs","sm","md","lg"],"mappings":"6EAAAA,EAAAC,QAAiBC,EAAAC,EAAuB,uDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,uDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,0DCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,qDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,uDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,sDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,yDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,uDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,sDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,uDCAxCH,EAAAC,QAAiBC,EAAAC,EAAuB,2cC0EzBC,MA7Df,WAEI,OACIC,IAAAC,cAACC,IAAS,CAACC,UAAU,cAAcC,GAAG,2BAClCJ,IAAAC,cAAA,MAAIE,UAAU,UAAS,kBACvBH,IAAAC,cAAA,SAAG,2CACHD,IAAAC,cAAA,UAAI,oBACbD,IAAAC,cAAA,OAAKE,UAAU,qBACdH,IAAAC,cAACI,IAAI,KACJL,IAAAC,cAAA,OAAKK,IAAKC,IAAQC,IAAI,mBAAmBC,MAAO,OAEjDT,IAAAC,cAAA,KAAGE,UAAU,gBAAe,yFAI7BH,IAAAC,cAAA,UAAI,YACJD,IAAAC,cAAA,aACCD,IAAAC,cAAA,aACCD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,SACJD,IAAAC,cAAA,MAAIE,UAAU,iBAAgB,YAE/BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKI,IAAUF,IAAI,YAAYL,UAAU,kBAClDH,IAAAC,cAAA,UAAI,UAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKK,IAAaH,IAAI,WAAWL,UAAU,kBACpDH,IAAAC,cAAA,UAAI,aAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKM,IAAUJ,IAAI,QAAQL,UAAU,kBAC9CH,IAAAC,cAAA,UAAI,UAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKO,IAAQL,IAAI,UAAUL,UAAU,kBAC9CH,IAAAC,cAAA,UAAI,QAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKQ,IAASN,IAAI,OAAOL,UAAU,kBAC5CH,IAAAC,cAAA,UAAI,SAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,YAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,OAAKK,IAAKS,IAAYP,IAAI,UAAUL,UAAU,kBAClDH,IAAAC,cAAA,UAAI,gBC5CKe,MAbf,WAEI,OACIhB,IAAAC,cAACC,IAAS,CAACC,UAAU,cAAcC,GAAG,oBAClCJ,IAAAC,cAAA,MAAIE,UAAU,UAAS,WACvBH,IAAAC,cAAA,SAAG,wECoGAgB,MApGf,WACI,IAAMC,EAAQC,iBAAO,MACfC,EAASD,iBAAO,MAMtB,OAJAE,oBAAU,cAKNrB,IAAAC,cAACC,IAAS,CAACC,UAAU,cAAcC,GAAG,mBAClCJ,IAAAC,cAAA,MAAIE,UAAU,QAAO,UACrBH,IAAAC,cAACqB,IAAG,KACAtB,IAAAC,cAACsB,IAAG,KACfvB,IAAAC,cAACI,IAAI,KACJL,IAAAC,cAAA,SAAOE,UAAU,cAAcC,GAAG,QAAQK,MAAM,MAAMe,OAAO,MAAMC,UAAQ,EACzDC,IAAKR,KAExBlB,IAAAC,cAACI,IAAI,KACJL,IAAAC,cAAA,UAAQE,UAAU,cAAcC,GAAG,SAASK,MAAM,MAAMe,OAAO,MAC7CE,IAAKN,MAGbpB,IAAAC,cAACsB,IAAG,KACAvB,IAAAC,cAAA,SAAG,iFCcR0B,MAvCf,WAEI,OAEA3B,IAAAC,cAACC,IAAS,CAACC,UAAU,cAAcC,GAAG,oBACxCJ,IAAAC,cAAA,MAAIE,UAAU,SAAQ,0BACtBH,IAAAC,cAAA,UAAI,kBACJD,IAAAC,cAAA,WACCD,IAAAC,cAAA,UAAI,uBACJD,IAAAC,cAAA,OAAKE,UAAU,kBACdH,IAAAC,cAAA,OAAKK,IAAKsB,IAASpB,IAAI,kBAAkBL,UAAU,iBACnDH,IAAAC,cAAA,SAAG,kLAOLD,IAAAC,cAAA,WACCD,IAAAC,cAAA,UAAI,gBACJD,IAAAC,cAAA,OAAKE,UAAU,kBACdH,IAAAC,cAAA,OAAKK,IAAKuB,IAAUrB,IAAI,mBAAmBL,UAAU,iBACrDH,IAAAC,cAAA,SAAG,8MAIJD,IAAAC,cAAA,UAAI,sBACJD,IAAAC,cAAA,OAAKE,UAAU,kBACfH,IAAAC,cAAA,OAAKK,IAAKwB,IAAUtB,IAAI,mBAAmBL,UAAU,iBACpDH,IAAAC,cAAA,SAAG,4SC4GQ8B,MA5If,WAEI,OAEA/B,IAAAC,cAACC,IAAS,CAACC,UAAU,4BAA4BC,GAAG,eACtDJ,IAAAC,cAAA,MAAIE,UAAU,QAAO,oBACrBH,IAAAC,cAAA,UAAI,WACJD,IAAAC,cAAA,SAAG,yIACmID,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,sBAAqB,+BAA+B,KAAEhC,IAAAC,cAAA,KAAGE,UAAY,OAAM6B,KAAK,cAAa,qBAAqB,kLAA+KhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,sBAAqB,+BAA+B,uBAAoBhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAM,gBAAe,kBAAkB,+HAA4HhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,cAAa,qBAAqB,0OAAuOhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,iBAAgB,4BAA4B,sJAAmJhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,iBAAgB,4BAA4B,mRAAgRhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAK,aAAY,2BAA2B,MAGrnDhC,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,SAAG,+BACyBD,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAO,iBAAgB,iBAAiB,mBAAgBhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAO,mBAAkB,mBAAmB,4BAAyBhC,IAAAC,cAAA,KAAGE,UAAY,OAAO6B,KAAO,iBAAgB,mBAAmB,uyBAErQhC,IAAAC,cAAA,UAAI,YACJD,IAAAC,cAAA,SAAG,62BAGHD,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,IAACD,IAAAC,cAAA,SAAGD,IAAAC,cAAA,SAAG,wCAAwC,gTAAgT,KAEnWD,IAAAC,cAAA,UAAID,IAAAC,cAAA,SAAG,wBAAwB,sRAE/BD,IAAAC,cAAA,UAAID,IAAAC,cAAA,SAAG,kCAAkC,wXAEzCD,IAAAC,cAAA,UAAID,IAAAC,cAAA,SAAG,gBAAgB,iLAGxBD,IAAAC,cAAA,UAAI,aACJD,IAAAC,cAAA,SAAOE,UAAU,gBAChBH,IAAAC,cAAA,aACCD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,QACJD,IAAAC,cAAA,UAAI,QACJD,IAAAC,cAAA,UAAI,SAELD,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,gBACJD,IAAAC,cAAA,UAAI,oBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,aACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,SACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,SACJD,IAAAC,cAAA,UAAI,mBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,eAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,mBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,qBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,YACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,eAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,kBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,UAAI,WACJD,IAAAC,cAAA,UAAI,iBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAG5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,oBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,qBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,WACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,oBACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,cAE5BH,IAAAC,cAAA,UACCD,IAAAC,cAAA,WACAD,IAAAC,cAAA,UAAI,2BACJD,IAAAC,cAAA,MAAIE,UAAU,cAAa,gBAI9BH,IAAAC,cAAA,UAAI,cACJD,IAAAC,cAAA,UACAD,IAAAC,cAAA,MAAIG,GAAK,kBAAiB,iGAA8FJ,IAAAC,cAAA,KAAG+B,KAAK,kGAAiG,oGAEjOhC,IAAAC,cAAA,MAAIG,GAAK,qBAAoB,2IAA8HJ,IAAAC,cAAA,KAAG+B,KAAO,gDAA+C,kDAEpNhC,IAAAC,cAAA,MAAIG,GAAK,gBAAe,6HAA0HJ,IAAAC,cAAA,KAAG+B,KAAK,gDAA+C,mDAEzMhC,IAAAC,cAAA,MAAIG,GAAK,iBAAgB,oFAAiFJ,IAAAC,cAAA,KAAG+B,KAAK,8CAA6C,+CAE/JhC,IAAAC,cAAA,MAAIG,GAAK,YAAW,yLAAsLJ,IAAAC,cAAA,KAAG+B,KAAO,qCAAoC,sCAExPhC,IAAAC,cAAA,MAAIG,GAAK,gBAAe,iFAA8EJ,IAAAC,cAAA,KAAG+B,KAAK,4EAA2E,6EAEzLhC,IAAAC,cAAA,MAAIG,GAAK,aAAY,0QAAkQJ,IAAAC,cAAA,KAAG+B,KAAK,gDAA+C,iDAE9UhC,IAAAC,cAAA,MAAIG,GAAK,gBAAe,qEAAkEJ,IAAAC,cAAA,KAAG+B,KAAO,uIAAsI,6JCpH7NC,MAff,WAEI,OACIjC,IAAAC,cAACC,IAAS,CAACC,UAAU,iCAAiC+B,MAAM,SACjElC,IAAAC,cAAA,OAAKK,IAAK6B,IAAQ3B,IAAI,UAAUL,UAAU,aACjCH,IAAAC,cAAA,UAAID,IAAAC,cAAA,KAAG+B,KAAK,qBAAoB,YAChChC,IAAAC,cAAA,UAAID,IAAAC,cAAA,KAAG+B,KAAK,gBAAe,qBAC3BhC,IAAAC,cAAA,UAAID,IAAAC,cAAA,KAAG+B,KAAK,4BAA2B,mBACvChC,IAAAC,cAAA,UAAID,IAAAC,cAAA,KAAG+B,KAAK,oBAAmB,WAC/BhC,IAAAC,cAAA,UAAID,IAAAC,cAAA,KAAG+B,KAAK,qBAAoB,cCC/BI,IAASC,WAAWC,SAASC,eAAe,SACpDC,OACHxC,IAAAC,cAACD,IAAMyC,WAAU,KACfzC,IAAAC,cAACC,IAAS,KACRF,IAAAC,cAACqB,IAAG,KACFtB,IAAAC,cAACsB,IAAG,CAACmB,GAAI,EAAGC,GAAI,EAAGC,GAAI,EAAGC,GAAI,GAC5B7C,IAAAC,cAACgC,EAAS,OAEZjC,IAAAC,cAACsB,IAAG,KACFvB,IAAAC,cAAC0B,EAAa,MACd3B,IAAAC,cAAC8B,EAAe,MAChB/B,IAAAC,cAACF,EAAoB,MACrBC,IAAAC,cAACgB,EAAY,MACbjB,IAAAC,cAACe,EAAa","file":"static/js/main.47e8ba20.chunk.js","sourcesContent":["module.exports = __webpack_public_path__ + \"static/media/cnn_3.f61ecb84.png\";","module.exports = __webpack_public_path__ + \"static/media/happy.554372ac.png\";","module.exports = __webpack_public_path__ + \"static/media/surprise.b24d6534.png\";","module.exports = __webpack_public_path__ + \"static/media/sad.d52cc55f.png\";","module.exports = __webpack_public_path__ + \"static/media/angry.db0edcfb.png\";","module.exports = __webpack_public_path__ + \"static/media/fear.ba6177a4.png\";","module.exports = __webpack_public_path__ + \"static/media/neutral.1848481f.png\";","module.exports = __webpack_public_path__ + \"static/media/silas.459b2998.jpg\";","module.exports = __webpack_public_path__ + \"static/media/rama.dcb81d6b.jpg\";","module.exports = __webpack_public_path__ + \"static/media/maria.1e4f5d7a.png\";","module.exports = __webpack_public_path__ + \"static/media/UW.6269965e.png\";","\r\nimport React from 'react';\r\nimport Container from 'react-bootstrap/Container';\r\nimport cnnPic from '../Figures/cnn_3.png';\r\nimport Zoom from 'react-medium-image-zoom'\r\nimport 'react-medium-image-zoom/dist/styles.css'\r\nimport happyPic from '../Figures/Emotions/happy.png';\r\nimport surprisePic from '../Figures/Emotions/surprise.png';\r\nimport sadPic from '../Figures/Emotions/sad.png';\r\nimport angryPic from '../Figures/Emotions/angry.png';\r\nimport fearPic from '../Figures/Emotions/fear.png';\r\nimport neutralPic from '../Figures/Emotions/neutral.png';\r\n\r\nfunction ImplementationScreen() {\r\n\r\n    return (\r\n        <Container className='myContainer' id='ImplementationContainer'>\r\n            <h1 className='purple'>Implementation</h1>\r\n            <p>Our implementation was great because...</p>\r\n            <h3>CNN Architecture</h3>\r\n\t\t\t<div className=\"largeImageSection\">\r\n\t\t\t\t<Zoom>\r\n\t\t\t\t\t<img src={cnnPic} alt=\"CNN Architecture\" width={800}></img>\r\n\t\t\t\t</Zoom>\r\n\t\t\t\t<p className=\"imageCaption\">\r\n\t\t\t\t\t This is a diagram that illustrated the architecture of our cnn model. Click to Zoom.\r\n\t\t\t\t</p>\r\n\t\t\t</div>\r\n\t\t\t<h3>Emotions</h3>\r\n\t\t\t<table>\r\n\t\t\t\t<tbody>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<th>Image</th>\r\n\t\t\t\t\t\t<th className='cellFullWidth'>Emotion</th>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={happyPic} alt=\"Happiness\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Happy</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={surprisePic} alt=\"Surprise\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Surprise</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={angryPic} alt=\"Angry\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Anger</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={sadPic} alt=\"Sadness\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Sad</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={fearPic} alt=\"Fear\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Fear</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td></td>\r\n\t\t\t\t\t\t<td>Disgust</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t\t<tr>\r\n\t\t\t\t\t\t<td><img src={neutralPic} alt=\"Neutral\" className=\"emotionImage\"></img></td>\r\n\t\t\t\t\t\t<td>Neutral</td>\r\n\t\t\t\t\t</tr>\r\n\t\t\t\t</tbody>\r\n\t\t\t</table>\r\n\r\n\r\n\r\n\r\n        </Container>\r\n\r\n    );\r\n}\r\n\r\nexport default ImplementationScreen;","\r\nimport React from 'react';\r\nimport Container from 'react-bootstrap/Container';\r\n\r\nfunction ResultsScreen() {\r\n\r\n    return (\r\n        <Container className='myContainer' id='ResultsContainer'>\r\n            <h1 className='orange'>Results</h1>\r\n            <p>\r\n                Our results were great because...\r\n            </p>\r\n        </Container>\r\n\r\n    );\r\n}\r\n\r\nexport default ResultsScreen;","import React, { useEffect, useRef } from \"react\";\r\nimport Container from 'react-bootstrap/Container';\r\nimport Row from 'react-bootstrap/Row';\r\nimport Col from 'react-bootstrap/Col';\r\nimport Zoom from 'react-medium-image-zoom'\r\nimport 'react-medium-image-zoom/dist/styles.css'\r\nimport * as tf from \"@tensorflow/tfjs\";\r\n\r\n\r\nfunction StreamScreen() {\r\n    const video = useRef(null);\r\n    const canvas = useRef(null);\r\n\r\n    useEffect(() => {\r\n        //logic(); //Fix this\r\n      });\r\n\r\n    return (\r\n        <Container className='myContainer' id='StreamContainer'>\r\n            <h1 className='blue'>Stream</h1>\r\n            <Row>\r\n                <Col>\r\n\t\t\t\t\t<Zoom>\r\n\t\t\t\t\t\t<video className='borderClass' id=\"video\" width=\"640\" height=\"480\" autoPlay\r\n                        ref={video}></video>\r\n\t\t\t\t\t</Zoom>\r\n\t\t\t\t\t<Zoom>\r\n\t\t\t\t\t\t<canvas className='borderClass' id=\"canvas\" width=\"640\" height=\"480\"\r\n                        ref={canvas}></canvas>\r\n\t\t\t\t\t</Zoom>\r\n                </Col>\r\n                <Col>\r\n                    <p>Check out this demo</p>\r\n                </Col>\r\n            </Row>\r\n        </Container>\r\n\r\n    );\r\n}\r\n\r\nfunction logic()\r\n{\r\n    let cv = \"\";\r\n    // Remove once cv is defined\r\n    const video = document.getElementById('video');\r\n    const canvas = document.getElementById('canvas');\r\n    const context = canvas.getContext('2d');\r\n\r\n    navigator.mediaDevices.getUserMedia({ video: true })\r\n        .then(function (stream) {\r\n            video.srcObject = stream;\r\n            video.play();\r\n        })\r\n        .catch(function (err) {\r\n            console.log(\"An error occurred: \" + err);\r\n        });\r\n\r\n    const faceCascade = new cv.CascadeClassifier();\r\n    const faceCascadeFile = 'haarcascade_frontalface_default.xml';\r\n    faceCascade.load(faceCascadeFile);\r\n\r\n    async function processVideo() {\r\n        let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);\r\n        let gray = new cv.Mat();\r\n        let faces = new cv.RectVector();\r\n\r\n        context.drawImage(video, 0, 0, canvas.width, canvas.height);\r\n        let imageData = context.getImageData(0, 0, canvas.width, canvas.height);\r\n        src.data.set(imageData.data);\r\n\r\n        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);\r\n        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, [0, 0], [video.width, video.height]);\r\n\r\n        // Load the pre-trained model\r\n        const model = await tf.loadLayersModel('emotion_detection_model.h5');\r\n\r\n        // Extract features and classify emotions using the pre-trained model\r\n        for (let i = 0; i < faces.size(); ++i) {\r\n            let face = faces.get(i);\r\n            let faceImg = gray.roi(face);\r\n            cv.resize(faceImg, faceImg, new cv.Size(48, 48));\r\n            tf.tidy(() => {\r\n                let tensor = tf.browser.fromPixels(faceImg).mean(2).toFloat().div(255.0).expandDims(0);\r\n                let prediction = model.predict(tensor);\r\n                let emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'];\r\n                let predictionData = prediction.dataSync();\r\n                let maxIndex = 0;\r\n                for (let j = 1; j < predictionData.length; ++j) {\r\n                    if (predictionData[j] > predictionData[maxIndex]) {\r\n                        maxIndex = j;\r\n                    }\r\n                }\r\n                let emotion = emotions[maxIndex];\r\n                let textSize = Math.max(face.width / 10, 16);\r\n                context.font = textSize + \"px Arial\";\r\n                context.fillStyle = \"red\";\r\n                context.fillText(emotion, face.x + 0.5 * (face.width - textSize * emotion.length), face.y - 5);\r\n            });\r\n            faceImg.delete();\r\n        }\r\n\r\n        requestAnimationFrame(processVideo);\r\n    }\r\n\r\n    video.addEventListener('play', function() {\r\n        requestAnimationFrame(processVideo);\r\n    });\r\n}\r\n\r\nexport default StreamScreen;","\r\nimport React from 'react';\r\nimport Container from 'react-bootstrap/Container';\r\nimport silasPic from '../Figures/silas.jpg';\r\nimport ramaPic from '../Figures/rama.jpg';\r\nimport mariaPic from '../Figures/maria.png';\r\n\r\nfunction WelcomeScreen() {\r\n\r\n    return (\r\n\r\n    <Container className='myContainer' id='WelcomeContainer'>\r\n\t\t<h1 className='green'>Welcome to our website</h1>\r\n\t\t<h2>Meet the team:</h2>\r\n\t\t<div>\r\n\t\t\t<h3>Ramapriya Ranganath</h3>\r\n\t\t\t<div className=\"welcomeSection\">\r\n\t\t\t\t<img src={ramaPic} alt=\"Picture of Rama\" className=\"welcomeImage\"></img>\r\n\t\t\t\t<p>\r\n\t\t\t\tI am Ramapriya master's student from UW Madison CS Department.\r\n\t\t\t\tBefore joining here, I was working in Microsoft Research India.\r\n\t\t\t\tMy areas of interest are ML, systems and HCI.\r\n\t\t\t\t</p>\r\n\t\t\t</div>\r\n\t\t</div>\r\n\t\t<div>\r\n\t\t\t<h3>Silas Morris</h3>\r\n\t\t\t<div className=\"welcomeSection\">\r\n\t\t\t\t<img src={silasPic} alt=\"Picture of Silas\" className=\"welcomeImage\"></img>\r\n\t\t\t\t<p>\r\n\t\t\t\t I'm a second year CS Masters student at UW and I'm hoping to graduate in May 2023. I moved to Madison in the summer of 2016 from Conroe, Texas and I'm currently working as a software developer at Epic.\r\n\t\t\t\t</p>\r\n\t\t\t</div>\r\n\t\t\t<h3>Maria Elisa Montes</h3>\r\n\t\t\t<div className=\"welcomeSection\">\r\n\t\t\t<img src={mariaPic} alt=\"Picture of Maria\" className=\"welcomeImage\"></img>\r\n\t\t\t\t<p>\r\n\t\t\t\t Hi my name is Maria. I grew up in Guanajuato, Mexico where I got my bachelors in Agronomy Engineering. Last January I came to Madison to start a PhD. in Animal Sciences focusing on precision livestock farming, specifically with dairy cows. In my free time I dance ballet and train gymnastics.\r\n\t\t\t\t</p>\r\n\t\t\t</div>\r\n\t\t</div>\r\n    </Container>\r\n\r\n    );\r\n}\r\n\r\nexport default WelcomeScreen;","import React from 'react';\r\nimport Container from 'react-bootstrap/Container';\r\n\r\n\r\nfunction ProjectProposal() {\r\n\r\n    return (\r\n\r\n    <Container className='myContainer pinkContainer' id='PPContainer'>\r\n\t\t<h1 className='pink'>Project proposal</h1>\r\n\t\t<h2>Problem</h2>\r\n\t\t<p>\r\n\t\tEmotion recognition systems identify features in verbal and non-verbal communication to identify and quantify the emotions expressed (<a className = 'cite' href=\"#fragopanagos_2005\">Fragopanagos & Taylor, 2005</a>; <a className = 'cite'href=\"#zhao_2020\">Zhao et al., 2020</a>). Data on users' emotional reactions when interacting with online applications is valuable for a wide range of fields education, healthcare, customer service, entertainment (<a className = 'cite' href=\"#fragopanagos_2005\">Fragopanagos & Taylor, 2005</a>), and criminology (<a className = 'cite' href= \"podolez_2022\">Podoletz, 2022</a>). The main signals in emotion analysis are facial expressions, speech, arm gestures, language, and physiological patterns (<a className = 'cite' href=\"#zhao_2020\">Zhao et al., 2020</a>). Emotion recognition from facial expressions involves computer vision, machine learning, and deep learning algorithms. In the context of online applications, the output must be accurate, real-time, and computationally efficient (<a className = 'cite' href=\"#hossain_2017\">Hossain & Muhammad, 2017</a>). Models that analyze images or complete video sequences do not provide an immediate output, therefore, are not suitable for online applications (<a className = 'cite' href=\"#hossain_2017\">Hossain & Muhammad, 2017</a>). Although different frameworks have been proposed, identifying emotions from facial expressions commonly involves face detection, feature extraction, and facial expression classification. In the case of video, dynamic features are extracted using temporal segmentation (<a className = 'cite' href=\"#suk_2014\">Suk & Prabhakaran, 2014</a>).  \r\n\t\r\n\t\t</p>\r\n\t\t<h2>Motivation</h2>\r\n\t\t<p>\r\n\t\tAutomated customer service (<a className = 'cite' href = \"#zendesk_2022\">Zendesk, 2022</a>), hybrid work (<a className = 'cite' href = \"#accenture_2021\">Accenture, 2021</a>), and distance learning <a className = 'cite' href = \"#venable_2022\">(Venable, 2022)</a> are becoming more common, raising the need for natural and personalized interactions with computers. Not only is emotional analysis essential for human-computer interaction but it is also essential for the study of human behavior.  In the gaming industry where, they need real time feedback during the beta testing phase, the company can use our tool to detect the emotions depicted by the testers to get an overall quality of the game. Facial emotion recognition can also be implemented in video from CCTV cameras, providing valuable data for crime prevention and investigation. Because this project will be presented in a web format, we were motivated to focus on emotion analysis for online applications. Our goal is that instructors and anyone that visits our website can interact with our project. \r\n\t\t</p>\r\n\t\t<h2>Approach</h2>\r\n\t\t<p>\r\n\t\tOur objective is to develop a program that identifies emotion in real-time video captured through a webcam. We will use an open-source data set to train a deep learning model.  The model uses a cascaded classifier to detect faces in the video frames. The grayscale face region is then passed through the trained model, which classifies facial expressions as anger, disgust, fear, happiness, sadness, surprise, or neutral. This is an already existing framework for emotion recognition which will allow us to compare the performance and accuracy of our implementation with previous work. We will also consider the application of real-time emotion recognition for crime prevention and incorporating object detection. Object detection will not only ensure that emotions are only assigned to persons but also be used for future correlations between objects and emotional states. \r\n\t\t</p>\r\n\t\t<h2>Milestones</h2>\r\n\t\t<ul>\r\n\t\t\t<li> <p><b>Data collection and data assessment.</b> Since this project will use an open-source data set, data preparation will not be needed. However, it is essential to assess the quality of the images in the data set. We are looking for a data set with about 3,000 images in each class that considers different ethnicities across emotion categories.</p> </li>\r\n\t\r\n\t\t\t<li><b>Program development.</b> For this project, we will develop a python code that uses OpenCV, Keras, and TensorFlow libraries to perform real-time facial emotion recognition. It uses a pre-trained deep learning model to predict a person's emotion based on their facial expression captured by a webcam.</li>\r\n\t\t\t\r\n\t\t\t<li><b>Website and model integration.</b> will create a website using React. This website will run an emotion recognition program. The site will request permission to open the webcam. Once the webcam is activated, the video will be displayed on the screen, and a frame indicating the user's emotion will be displayed around the face. Readme instructions on the web page will make it crystal clear to run the code.</li>\r\n\r\n\t\t\t<li><b>Beta testing</b> after completing the requirements for the course project. The team plans to test the program on a practical application and receive feedback from authorities in the field.</li>\r\n\t\t</ul>\r\n\t\r\n\t\t<h2>Timetable</h2>\r\n\t\t<table className='center_table'>\r\n\t\t\t<tbody>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<th>Type</th>\r\n\t\t\t\t\t<th>Task</th>\r\n\t\t\t\t\t<th>Date</th>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td>Deliverables</td>\r\n\t\t\t\t\t<td>Project proposal</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">2/19/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Mid-term </td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Final</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">4/30/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td>Model</td>\r\n\t\t\t\t\t<td>Data collection</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">2/05/2023 </td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Data assessment</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">2/05/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Preliminary model</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">2/19/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Training</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023 </td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Evaluation</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Implementation</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td>Website</td>\r\n\t\t\t\t\t<td>Site creation</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">2/19/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Content creation</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Model integration</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">3/02/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Hosting</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">4/22/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Web cam function</td>\r\n\t\t\t\t\t<td className=\"rightAlign\">4/22/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t\t<tr>\r\n\t\t\t\t\t<td></td>\r\n\t\t\t\t\t<td>Complete functionality </td>\r\n\t\t\t\t\t<td className=\"rightAlign\">4/24/2023</td>\r\n\t\t\t\t</tr>\r\n\t\t\t</tbody>\r\n\t\t</table>\r\n\t\t<h2>References</h2>\r\n\t\t<ul>\r\n\t\t<li id = \"accenture_2021\"> Accenture. (2021). The future of work: Productive anywhere. Retrieved in February 2023 from: <a href=\"https://www.accenture.com/_acnmedia/PDF-155/Accenture-Future-Of-Work-Global-Report.pdf#zoom=40\">https://www.accenture.com/_acnmedia/PDF-155/Accenture-Future-Of-Work-Global-Report.pdf#zoom=40 </a></li> \r\n\t\t\r\n\t\t<li id = \"fragopanagos_2005\">Fragopanagos, N., & Taylor, J. G. (2005). Emotion recognition in human–computer interaction. Neural Networks, 18(4), 389–405. <a href = \"https://doi.org/10.1016/j.neunet.2005.03.006\"> https://doi.org/10.1016/j.neunet.2005.03.006</a></li>\r\n\t\t\t\r\n\t\t<li id = \"hossain_2017\">Hossain, M. S., & Muhammad, G. (2017). An emotion recognition system for mobile applications. IEEE Access (5), 2281-2287. <a href=\"https://ieeexplore.ieee.org/document/7862118\"> https://ieeexplore.ieee.org/document/7862118 </a></li>\r\n\t\t\r\n\t\t<li id = \"podoletz_2022\">Podoletz, L. (2022). We have to talk about emotional AI and crime. AI & Society. <a href='https://doi.org/10.1007/s00146-022-01435-w'>https://doi.org/10.1007/s00146-022-01435-w</a>  \r\n\t\t</li>\r\n\t\t<li id = \"suk_0214\"> Suk, M., & Prabhakaran, B. (2014). Real-Time Mobile Facial Expression Recognition System -- A Case Study. 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops. <a href = \"https://doi:10.1109/cvprw.2014.25\">https://doi:10.1109/cvprw.2014.25</a></li>\r\n\t\r\n\t\t<li id = \"venable_2022\"> Venable, M. A. (2022). 2022 Online Education Trends Report. BestColleges.com <a href='https://www.bestcolleges.com/research/annual-trends-in-online-education/'>https://www.bestcolleges.com/research/annual-trends-in-online-education/</a></li>\r\n\t\t\r\n\t\t<li id = \"zhao_2020\">Zhao, J., Zhang, A., Rau, P.-L. P., Dong, L., & Ge, L. (2020). Trends in human-computer interaction in the 5G era: Emerging life scenarios with 5G networks. Cross-Cultural Design. User Experience of Products, Services, and Intelligent Environments, 699–710. <a href=\"https://doi.org/10.1007/978-3-030-49788-0_53\">https://doi.org/10.1007/978-3-030-49788-0_53</a></li>\r\n\t\t\r\n\t\t<li id = \"zendesk_2022\">Zendesk. (2022). CX Trends 2022. Retrieved in February 2023 from: <a href = \"https://cdn2.assets-servd.host/paltry-coyote/production/exports/1e02568f10207f5f7052a41fa28de0a4/zendesk-cx-trends-2022-report.pdf \"> https://cdn2.assets-servd.host/paltry-coyote/production/exports/1e02568f10207f5f7052a41fa28de0a4/zendesk-cx-trends-2022-report.pdf</a></li>\r\n\t\t\r\n\t\t</ul>\r\n\t</Container>\r\n\r\n    );\r\n}\r\n\r\nexport default ProjectProposal;","\r\nimport React from 'react';\r\nimport Container from 'react-bootstrap/Container';\r\nimport uwLogo from '../Figures/UW.png';\r\n\r\nfunction Navigator() {\r\n\r\n    return (\r\n        <Container className='navigatorContainer myContainer' fluid=\"false\">\r\n\t\t\t<img src={uwLogo} alt=\"UW logo\" className=\"navImage\"></img>\r\n            <h4><a href=\"#WelcomeContainer\">Welcome</a></h4>\r\n            <h4><a href=\"#PPContainer\">Project Proposal</a></h4>\r\n            <h4><a href=\"#ImplementationContainer\">Implementation</a></h4>\r\n            <h4><a href=\"#StreamContainer\">Stream</a></h4>\r\n            <h4><a href=\"#ResultsContainer\">Results</a></h4>\r\n        </Container>\r\n\r\n    );\r\n}\r\n\r\nexport default Navigator;","import React from 'react';\r\nimport ReactDOM from 'react-dom/client';\r\n\r\nimport './index.css';\r\nimport 'bootstrap/dist/css/bootstrap.min.css';\r\n\r\nimport ImplementationScreen from './components/ImplementationScreen';\r\nimport ResultsScreen from './components/ResultsScreen';\r\nimport StreamScreen from './components/StreamScreen';\r\nimport WelcomeScreen from './components/WelcomeScreen';\r\nimport ProjectProposal from './components/ProjectProposal';\r\nimport Navigator from './components/Navigator';\r\nimport Col from 'react-bootstrap/Col';\r\nimport { Container, Row } from 'react-bootstrap';\r\n\r\nconst root = ReactDOM.createRoot(document.getElementById('root'));\r\nroot.render(\r\n  <React.StrictMode>\r\n    <Container>\r\n      <Row>\r\n        <Col xs={6} sm={5} md={4} lg={3}>\r\n          <Navigator />\r\n        </Col>\r\n        <Col>\r\n          <WelcomeScreen />\r\n          <ProjectProposal/>\r\n          <ImplementationScreen />\r\n          <StreamScreen />\r\n          <ResultsScreen />\r\n        </Col>\r\n      </Row>\r\n    </Container>\r\n  </React.StrictMode>\r\n);"],"sourceRoot":""}